import streamlit as st
import pandas as pd
from collections import defaultdict
import sys
import re
import uuid
import os

# å‡½æ•°ï¼šä»è°ƒç ” Excel ç”Ÿæˆè¡¨å¤´ Excel
def generate_header_from_survey(survey_file='survey-JP.xlsx', output_file='header-JP.xlsx', sheet_name=0):
    try:
        # è¯»å– Excel æ–‡ä»¶
        df_survey = pd.read_excel(survey_file, sheet_name=sheet_name)
        st.write(f"æˆåŠŸè¯»å–æ–‡ä»¶ï¼š{survey_file}ï¼Œæ•°æ®å½¢çŠ¶ï¼š{df_survey.shape}")
        st.write(f"åˆ—ååˆ—è¡¨: {list(df_survey.columns)}")
    except FileNotFoundError:
        st.error(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ {survey_file}ã€‚è¯·ç¡®ä¿æ–‡ä»¶å·²ä¸Šä¼ ã€‚")
        return None
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}")
        return None
    
    # æå–ç‹¬ç‰¹æ´»åŠ¨åç§°
    unique_campaigns = [name for name in df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'].dropna() if str(name).strip()]
    st.write(f"ç‹¬ç‰¹æ´»åŠ¨åç§°æ•°é‡: {len(unique_campaigns)}: {unique_campaigns}")
    
    # åˆ›å»ºæ´»åŠ¨åˆ° CPC/SKU/å¹¿å‘Šç»„é»˜è®¤ç«ä»·/é¢„ç®—/å¹¿å‘Šä½/ç™¾åˆ†æ¯” çš„æ˜ å°„
    non_empty_campaigns = df_survey[
        df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'].notna() & 
        (df_survey['å¹¿å‘Šæ´»åŠ¨åç§°'] != '')
    ]
    required_cols = ['CPC', 'SKU', 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·', 'é¢„ç®—', 'å¹¿å‘Šä½', 'ç™¾åˆ†æ¯”']
    if all(col in non_empty_campaigns.columns for col in required_cols):
        campaign_to_values = non_empty_campaigns.drop_duplicates(
            subset='å¹¿å‘Šæ´»åŠ¨åç§°', keep='first'
        ).set_index('å¹¿å‘Šæ´»åŠ¨åç§°')[required_cols].to_dict('index')
    else:
        campaign_to_values = {}
        st.warning(f"è­¦å‘Šï¼šç¼ºå°‘åˆ— {set(required_cols) - set(non_empty_campaigns.columns)}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    
    st.write(f"ç”Ÿæˆçš„å­—å…¸ï¼ˆæœ‰ {len(campaign_to_values)} ä¸ªæ´»åŠ¨ï¼‰: {campaign_to_values}")
    
    # å…³é”®è¯åˆ—ï¼šä» suzhu/å®¿ä¸»-ç²¾å‡†è¯ï¼ˆç´¢å¼• 9ï¼‰åˆ° å¹¿æ³›è¯.2ï¼ˆç´¢å¼• 18ï¼‰
    keyword_columns = df_survey.columns[9:19]
    st.write(f"å…³é”®è¯åˆ—: {list(keyword_columns)}")
    
    # æ£€æŸ¥å…³é”®è¯é‡å¤
    duplicates_found = False
    st.write("### æ£€æŸ¥å…³é”®è¯é‡å¤")
    for col in keyword_columns:
        col_index = list(df_survey.columns).index(col) + 1
        col_letter = chr(64 + col_index) if col_index <= 26 else f"{chr(64 + (col_index-1)//26)}{chr(64 + (col_index-1)%26 + 1)}"
        kw_list = [kw for kw in df_survey[col].dropna() if str(kw).strip()]
        
        if len(kw_list) > len(set(kw_list)):
            duplicates_mask = df_survey[col].duplicated(keep=False)
            duplicates_df = df_survey[duplicates_mask][[col]].dropna()
            st.warning(f"è­¦å‘Šï¼š{col_letter} åˆ— ({col}) æœ‰é‡å¤å…³é”®è¯")
            for _, row in duplicates_df.iterrows():
                kw = str(row[col]).strip()
                count = (df_survey[col] == kw).sum()
                if count > 1:
                    st.write(f"  é‡å¤è¯: '{kw}' (å‡ºç° {count} æ¬¡)")
            duplicates_found = True
    
    if duplicates_found:
        st.error("æç¤ºï¼šç”±äºæ£€æµ‹åˆ°å…³é”®è¯é‡å¤ï¼Œæœ¬æ¬¡ä¸ç”Ÿæˆè¡¨æ ¼ã€‚è¯·æ¸…ç†é‡å¤åé‡è¯•ã€‚")
        return None
    
    st.write("å…³é”®è¯æ— é‡å¤ï¼Œç»§ç»­ç”Ÿæˆ...")
    
    # å¦å®šå…³é”®è¯èšåˆ
    neg_exact = [kw for kw in df_survey.get('å¦å®šç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]
    neg_phrase = [kw for kw in df_survey.get('å¦å®šè¯ç»„', pd.Series()).dropna() if str(kw).strip()]
    suzhu_extra_neg_exact = [kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦ç²¾å‡†', pd.Series()).dropna() if str(kw).strip()]
    suzhu_extra_neg_phrase = [kw for kw in df_survey.get('å®¿ä¸»é¢å¤–å¦è¯ç»„', pd.Series()).dropna() if str(kw).strip()]
    neg_asin = [kw for kw in df_survey.get('å¦å®šASIN', pd.Series()).dropna() if str(kw).strip()]
    
    # åˆ—å®šä¹‰
    columns = [
        'äº§å“', 'å®ä½“å±‚çº§', 'æ“ä½œ', 'å¹¿å‘Šæ´»åŠ¨ç¼–å·', 'å¹¿å‘Šç»„ç¼–å·', 'å¹¿å‘Šç»„åˆç¼–å·', 'å¹¿å‘Šç¼–å·', 'å…³é”®è¯ç¼–å·', 'å•†å“æŠ•æ”¾ ID',
        'å¹¿å‘Šæ´»åŠ¨åç§°', 'å¹¿å‘Šç»„åç§°', 'å¼€å§‹æ—¥æœŸ', 'ç»“æŸæ—¥æœŸ', 'æŠ•æ”¾ç±»å‹', 'çŠ¶æ€', 'æ¯æ—¥é¢„ç®—', 'SKU', 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·',
        'ç«ä»·', 'å…³é”®è¯æ–‡æœ¬', 'åŒ¹é…ç±»å‹', 'ç«ä»·æ–¹æ¡ˆ', 'å¹¿å‘Šä½', 'ç™¾åˆ†æ¯”', 'æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·'
    ]
    
    # é»˜è®¤å€¼
    product = 'å•†å“æ¨å¹¿'
    operation = 'Create'
    status = 'å·²å¯ç”¨'
    targeting_type = 'æ‰‹åŠ¨'
    bidding_strategy = 'åŠ¨æ€ç«ä»· - ä»…é™ä½'
    default_daily_budget = 12
    default_group_bid = 0.6
    
   # æ”¹è¿›çš„å…³é”®è¯ç±»åˆ«æå–é€»è¾‘
    def extract_keyword_categories(df_survey):
        categories = set()
        
        # ä»åˆ—åä¸­æå–æ‰€æœ‰å¯èƒ½çš„å…³é”®è¯ç±»åˆ«
        for col in df_survey.columns:
            col_lower = str(col).lower()
            
            # å¤„ç†å…³é”®è¯åˆ—
            if any(x in col_lower for x in ['ç²¾å‡†è¯', 'å¹¿æ³›è¯', 'ç²¾å‡†', 'å¹¿æ³›']):
                # å»é™¤åŒ¹é…ç±»å‹åç¼€
                for suffix in ['ç²¾å‡†è¯', 'å¹¿æ³›è¯', 'ç²¾å‡†', 'å¹¿æ³›']:
                    if col_lower.endswith(suffix):
                        prefix = col_lower[:-len(suffix)].strip()
                        # æŒ‰å¤šç§åˆ†éš”ç¬¦æ‹†åˆ†
                        parts = re.split(r'[/\-_\s\.]', prefix)
                        for part in parts:
                            if part and len(part) > 1:  # åªä¿ç•™æœ‰æ„ä¹‰çš„è¯
                                categories.add(part)
                        break
            
            # å¤„ç†ASINåˆ—
            elif 'asin' in col_lower and 'å¦å®š' not in col_lower:
                # å»é™¤ASINåç¼€
                prefix = col_lower.replace('asin', '').strip()
                # æŒ‰å¤šç§åˆ†éš”ç¬¦æ‹†åˆ†
                parts = re.split(r'[/\-_\s\.]', prefix)
                for part in parts:
                    if part and len(part) > 1:  # åªä¿ç•™æœ‰æ„ä¹‰çš„è¯
                        categories.add(part)
        
        # æ·»åŠ å·²çŸ¥çš„å…³é”®è¯ç±»åˆ«
        categories.update(['suzhu', 'å®¿ä¸»', 'case', 'åŒ…', 'tape'])
        
        # ç§»é™¤ç©ºå­—ç¬¦ä¸²
        categories.discard('')
        
        return categories
    
    keyword_categories = extract_keyword_categories(df_survey)
    st.write(f"è¯†åˆ«åˆ°çš„å…³é”®è¯ç±»åˆ«: {keyword_categories}")
    
    # ç”Ÿæˆæ•°æ®è¡Œ
    rows = []
    
    # å‡½æ•°ï¼šä¸ºå•†å“å®šå‘æ´»åŠ¨æŸ¥æ‰¾åŒ¹é…çš„åˆ—
    def find_matching_asin_columns(campaign_name, df_survey, keyword_categories):
        # ä¿®æ”¹ï¼šå¹¿å‘Šæ´»åŠ¨åç§°å¿…é¡»è·Ÿåˆ—åå®Œå…¨ä¸€æ ·
        matching_columns = []
        for col in df_survey.columns:
            col_lower = str(col).lower()
            if str(col) == str(campaign_name) and 'asin' in col_lower and 'å¦å®š' not in col_lower:
                matching_columns.append(col)
                st.write(f"  åŒ¹é…çš„ASINåˆ—: {col} (å®Œå…¨åŒ¹é…æ´»åŠ¨åç§° {campaign_name})")
                break  # å‡è®¾åªæœ‰ä¸€ä¸ªå®Œå…¨åŒ¹é…çš„åˆ—
        
        if not matching_columns:
            st.write(f"  {campaign_name} æœªæ‰¾åˆ°å®Œå…¨åŒ¹é…çš„ASINåˆ—")
        
        return matching_columns

    # å‡½æ•°ï¼šæŸ¥æ‰¾åŒ¹é…çš„å…³é”®è¯åˆ—
    def find_matching_keyword_columns(campaign_name, df_survey, keyword_categories, keyword_columns, match_type):
        campaign_name_normalized = str(campaign_name).lower()
        
        # ç¡®å®šå…³é”®è¯ç±»åˆ«
        matched_categories = []
        for category in keyword_categories:
            if category and category in campaign_name_normalized:
                matched_categories.append(category)
        
        st.write(f"  åŒ¹é…çš„å…³é”®è¯ç±»åˆ«: {matched_categories}")
        
        if not matched_categories:
            st.write("  æ— åŒ¹é…çš„å…³é”®è¯ç±»åˆ«")
            return [], []
        
        # ç¡®å®šåŒ¹é…ç±»å‹å…³é”®è¯
        match_type_keywords = []
        if match_type == 'ç²¾å‡†':
            match_type_keywords = ['ç²¾å‡†', 'exact']
        elif match_type == 'å¹¿æ³›':
            match_type_keywords = ['å¹¿æ³›', 'broad']
        
        # æŸ¥æ‰¾åŒ¹é…çš„åˆ—
        matching_columns = []
        for col in keyword_columns:
            col_lower = str(col).lower()
            
            # æ£€æŸ¥åˆ—åæ˜¯å¦åŒ…å«åŒ¹é…ç±»å‹å…³é”®è¯
            has_match_type = any(keyword in col_lower for keyword in match_type_keywords)
            
            # æ£€æŸ¥åˆ—åæ˜¯å¦åŒ…å«ä»»ä½•åŒ¹é…çš„ç±»åˆ«
            has_category = any(category in col_lower for category in matched_categories)
            
            if has_match_type and has_category:
                matching_columns.append(col)
        
        st.write(f"  åŒ¹é…çš„åˆ—: {matching_columns}")
        
        # æå–å…³é”®è¯
        keywords = []
        for col in matching_columns:
            keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
        
        # å»é‡
        keywords = list(dict.fromkeys(keywords))
        st.write(f"  å…³é”®è¯æ•°é‡: {len(keywords)} (ç¤ºä¾‹: {keywords[:2] if keywords else 'æ— '})")
        
        return matching_columns, keywords
    
    # å‡½æ•°ï¼šæŸ¥æ‰¾å¦å®šå…³é”®è¯
    def find_neg_keywords(campaign_name, df_survey, keyword_categories, keyword_columns):
        campaign_name_normalized = str(campaign_name).lower()
        
        # ç¡®å®šå…³é”®è¯ç±»åˆ«
        matched_categories = []
        for category in keyword_categories:
            if category and category in campaign_name_normalized:
                matched_categories.append(category)
        
        if not matched_categories:
            return []
        
        # æŸ¥æ‰¾ç²¾å‡†å…³é”®è¯åˆ—
        neg_keywords = []
        for col in keyword_columns:
            col_lower = str(col).lower()
            if any(category in col_lower for category in matched_categories) and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                neg_keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
        
        # å»é‡
        neg_keywords = list(dict.fromkeys(neg_keywords))
        st.write(f"  ç²¾å‡†å¦å®šå…³é”®è¯æ•°é‡: {len(neg_keywords)} (ç¤ºä¾‹: {neg_keywords[:2] if neg_keywords else 'æ— '})")
        
        return neg_keywords
    
    # å‡½æ•°ï¼šæŸ¥æ‰¾äº¤å‰å¦å®šå…³é”®è¯
    def find_cross_neg_keywords(campaign_name, df_survey, keyword_categories, keyword_columns):
        campaign_name_normalized = str(campaign_name).lower()
        
        cross_neg_keywords = []
        
        # å¦‚æœæ˜¯å®¿ä¸»ç»„ï¼Œå¦å®šcaseç²¾å‡†è¯
        if any(x in campaign_name_normalized for x in ['suzhu', 'å®¿ä¸»']):
            # æŸ¥æ‰¾caseç²¾å‡†å…³é”®è¯ä½œä¸ºå¦å®šè¯
            for col in keyword_columns:
                col_lower = str(col).lower()
                if any(case_word in col_lower for case_word in ['case', 'åŒ…', 'tape']) and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                    cross_neg_keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
        
        # å¦‚æœæ˜¯caseç»„ï¼Œå¦å®šå®¿ä¸»ç²¾å‡†è¯
        elif any(x in campaign_name_normalized for x in ['case', 'åŒ…', 'tape']):
            # æŸ¥æ‰¾å®¿ä¸»ç²¾å‡†å…³é”®è¯ä½œä¸ºå¦å®šè¯
            for col in keyword_columns:
                col_lower = str(col).lower()
                if any(suzhu_word in col_lower for suzhu_word in ['suzhu', 'å®¿ä¸»']) and any(x in col_lower for x in ['ç²¾å‡†', 'exact']):
                    cross_neg_keywords.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
        
        # å»é‡
        cross_neg_keywords = list(dict.fromkeys(cross_neg_keywords))
        st.write(f"  äº¤å‰å¦å®šå…³é”®è¯æ•°é‡: {len(cross_neg_keywords)} (ç¤ºä¾‹: {cross_neg_keywords[:2] if cross_neg_keywords else 'æ— '})")
        
        return cross_neg_keywords
    
    for campaign_name in unique_campaigns:
        # è·å– CPCã€SKUã€å¹¿å‘Šç»„é»˜è®¤ç«ä»·ã€é¢„ç®—ã€å¹¿å‘Šä½ã€ç™¾åˆ†æ¯”
        if campaign_name in campaign_to_values:
            cpc = campaign_to_values[campaign_name]['CPC']
            sku = campaign_to_values[campaign_name]['SKU']
            group_bid = campaign_to_values[campaign_name]['å¹¿å‘Šç»„é»˜è®¤ç«ä»·']
            budget = campaign_to_values[campaign_name]['é¢„ç®—']
            ad_position = campaign_to_values[campaign_name]['å¹¿å‘Šä½']
            percentage = campaign_to_values[campaign_name]['ç™¾åˆ†æ¯”']
        else:
            cpc = 0.5
            sku = 'SKU-1'
            group_bid = default_group_bid
            budget = default_daily_budget
            ad_position = ''
            percentage = ''
        
        st.write(f"å¤„ç†æ´»åŠ¨: {campaign_name}")
        
        campaign_name_normalized = str(campaign_name).lower()
        
        # ç¡®å®šåŒ¹é…ç±»å‹
        is_exact = any(x in campaign_name_normalized for x in ['ç²¾å‡†', 'exact'])
        is_broad = any(x in campaign_name_normalized for x in ['å¹¿æ³›', 'broad'])
        is_asin = 'asin' in campaign_name_normalized
        match_type = 'ç²¾å‡†' if is_exact else 'å¹¿æ³›' if is_broad else 'ASIN' if is_asin else None
        st.write(f"  is_exact: {is_exact}, is_broad: {is_broad}, is_asin: {is_asin}, match_type: {match_type}")
        
        # æå–å…³é”®è¯ï¼ˆç”¨äºæ­£å‘å…³é”®è¯ï¼Œç²¾å‡†/å¹¿æ³›åŒ¹é…ï¼‰
        keywords = []
        matched_columns = []
        if is_exact or is_broad:
            matched_columns, keywords = find_matching_keyword_columns(
                campaign_name, df_survey, keyword_categories, keyword_columns, match_type
            )
        
        # æå–ç²¾å‡†å…³é”®è¯ï¼ˆç”¨äºå¹¿æ³›åŒ¹é…æ´»åŠ¨çš„å¦å®šå…³é”®è¯ï¼‰
        neg_keywords = []
        if is_broad:
            neg_keywords = find_neg_keywords(campaign_name, df_survey, keyword_categories, keyword_columns)
        
        # æå– ASINï¼ˆç”¨äºå•†å“å®šå‘ï¼‰
        asin_targets = []
        if is_asin:
            matching_columns = find_matching_asin_columns(campaign_name, df_survey, keyword_categories)
            for col in matching_columns:
                asin_targets.extend([kw for kw in df_survey[col].dropna() if str(kw).strip()])
            asin_targets = list(dict.fromkeys(asin_targets))
            st.write(f"  å•†å“å®šå‘ ASIN æ•°é‡: {len(asin_targets)} (ç¤ºä¾‹: {asin_targets[:2] if asin_targets else 'æ— '})")
        
        # å¹¿å‘Šæ´»åŠ¨è¡Œ
        rows.append([
            product, 'å¹¿å‘Šæ´»åŠ¨', operation, campaign_name, '', '', '', '', '',
            campaign_name, '', '', '', targeting_type, status, budget, '', '',
            '', '', '', bidding_strategy, '', '', ''
        ])
        
        # ç«ä»·è°ƒæ•´è¡Œ
        rows.append([
            'å•†å“æ¨å¹¿', 'ç«ä»·è°ƒæ•´', 'Create', campaign_name, '', '', '', '', '',
            campaign_name, campaign_name, '', '', 'æ‰‹åŠ¨', '', '', '', '',
            '', '', '', 'åŠ¨æ€ç«ä»· - ä»…é™ä½', ad_position, percentage, ''
        ])
        
        # å¹¿å‘Šç»„è¡Œ
        rows.append([
            product, 'å¹¿å‘Šç»„', operation, campaign_name, campaign_name, '', '', '', '',
            campaign_name, campaign_name, '', '', '', status, '', '', group_bid,
            '', '', '', '', '', '', ''
        ])
        
        # å•†å“å¹¿å‘Šè¡Œ
        rows.append([
            product, 'å•†å“å¹¿å‘Š', operation, campaign_name, campaign_name, '', '', '', '',
            campaign_name, campaign_name, '', '', '', status, '', sku, '',
            '', '', '', '', '', '', ''
        ])
        
        # å…³é”®è¯è¡Œï¼ˆä»…ç²¾å‡†/å¹¿æ³›åŒ¹é…ï¼‰
        if is_exact or is_broad:
            for kw in keywords:
                rows.append([
                    product, 'å…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '',
                    cpc, kw, match_type, '', '', '', ''
                ])
        
        # å¦å®šå…³é”®è¯è¡Œï¼ˆä»…ç²¾å‡†/å¹¿æ³›åŒ¹é…ï¼‰
        if is_exact:
            # åŸæœ‰è§„åˆ™ï¼šå…¨å±€å¦å®šç²¾å‡†å’Œå¦å®šè¯ç»„
            for kw in neg_exact:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                ])
            for kw in neg_phrase:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šè¯ç»„', '', '', '', ''
                ])
            
            # æ–°å¢ï¼šäº¤å‰å¦å®šè§„åˆ™ï¼ˆå®¿ä¸»ç²¾å‡†ç»„å¦å®šcaseç²¾å‡†è¯ï¼Œcaseç²¾å‡†ç»„å¦å®šå®¿ä¸»ç²¾å‡†è¯ï¼‰
            cross_neg_keywords = find_cross_neg_keywords(campaign_name, df_survey, keyword_categories, keyword_columns)
            for kw in cross_neg_keywords:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                ])
        elif is_broad:
            # å…¨å±€å¦å®šç²¾å‡†
            for kw in neg_exact:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                ])
            # å…¨å±€å¦å®šè¯ç»„
            for kw in neg_phrase:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šè¯ç»„', '', '', '', ''
                ])
            # åŒç±»çš„ç²¾å‡†å…³é”®è¯ä½œä¸ºå¦å®šç²¾å‡†
            for kw in neg_keywords:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                ])
            
            # äº¤å‰å¦å®šè§„åˆ™ï¼šå®¿ä¸»å¹¿æ³›ç»„å¦å®šcaseç²¾å‡†è¯ï¼Œcaseå¹¿æ³›ç»„å¦å®šå®¿ä¸»ç²¾å‡†è¯
            cross_neg_keywords = find_cross_neg_keywords(campaign_name, df_survey, keyword_categories, keyword_columns)
            
            # å¦‚æœæ˜¯å®¿ä¸»å¹¿æ³›ç»„ï¼Œæ·»åŠ å®¿ä¸»é¢å¤–å¦å®šè¯
            if any(x in campaign_name_normalized for x in ['suzhu', 'å®¿ä¸»']):
                for kw in suzhu_extra_neg_exact:
                    rows.append([
                        product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                        campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                        kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                    ])
                for kw in suzhu_extra_neg_phrase:
                    rows.append([
                        product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                        campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                        kw, 'å¦å®šè¯ç»„', '', '', '', ''
                    ])
            
            # æ·»åŠ äº¤å‰å¦å®šå…³é”®è¯
            for kw in cross_neg_keywords:
                rows.append([
                    product, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '', '',
                    kw, 'å¦å®šç²¾å‡†åŒ¹é…', '', '', '', ''
                ])
        
        # å•†å“å®šå‘å’Œå¦å®šå•†å“å®šå‘ï¼ˆä»… ASIN ç»„ï¼‰
        if is_asin:
            for asin in asin_targets:
                rows.append([
                    product, 'å•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '',
                    cpc, '', '', '', '', '', f'asin="{asin}"'
                ])
            for asin in neg_asin:
                rows.append([
                    product, 'å¦å®šå•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', '', '',
                    campaign_name, campaign_name, '', '', '', status, '', '', '',
                    '', '', '', '', '', '', f'asin="{asin}"'
                ])
    
    # åˆ›å»º DataFrame
    df_header = pd.DataFrame(rows, columns=columns)
    try:
        df_header.to_excel(output_file, index=False, engine='openpyxl')
        st.success(f"ç”Ÿæˆå®Œæˆï¼è¾“å‡ºæ–‡ä»¶ï¼š{output_file}ï¼Œæ€»è¡Œæ•°ï¼š{len(rows)}")
    except PermissionError:
        st.error(f"é”™è¯¯ï¼šæ— æ³•å†™å…¥ {output_file}ï¼Œè¯·ç¡®ä¿æ–‡ä»¶æœªè¢«å ç”¨æˆ–æœ‰å†™å…¥æƒé™ã€‚")
        return None
    
    # è°ƒè¯•è¾“å‡º
    keyword_rows = [row for row in rows if row[1] == 'å…³é”®è¯']
    st.write(f"å…³é”®è¯è¡Œæ•°é‡: {len(keyword_rows)}")
    if keyword_rows:
        st.write(f"ç¤ºä¾‹å…³é”®è¯è¡Œ: å®ä½“å±‚çº§={keyword_rows[0][1]}, å…³é”®è¯æ–‡æœ¬={keyword_rows[0][19]}, åŒ¹é…ç±»å‹={keyword_rows[0][20]}")
    
    product_targeting_rows = [row for row in rows if row[1] == 'å•†å“å®šå‘']
    st.write(f"å•†å“å®šå‘è¡Œæ•°é‡: {len(product_targeting_rows)}")
    if product_targeting_rows:
        st.write(f"ç¤ºä¾‹å•†å“å®šå‘è¡Œ: å®ä½“å±‚çº§={product_targeting_rows[0][1]}, ç«ä»·={product_targeting_rows[0][18]}, æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·={product_targeting_rows[0][24]}")
    
    levels = set(row[1] for row in rows)
    st.write(f"æ‰€æœ‰å®ä½“å±‚çº§: {levels}")
    
    st.write("ç”Ÿæˆçš„è¡¨æ ¼é¢„è§ˆï¼š")
    st.dataframe(df_header.head(20))  # æ˜¾ç¤ºå‰20è¡Œä½œä¸ºé¢„è§ˆ
    
    # æ·»åŠ ä¸‹è½½æŒ‰é’®
    with open(output_file, 'rb') as f:
        st.download_button(
            label='ä¸‹è½½ç”Ÿæˆçš„è¡¨å¤´æ–‡ä»¶ (header-JP.xlsx)',
            data=f.read(),
            file_name='header-JP.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
    
    return df_header

# Streamlit ä¸»ç•Œé¢
def main():
    st.title("ğŸŒ¸ SP-æ‰¹é‡æ¨¡ç‰ˆç”Ÿæˆå·¥å…·ï¼ˆJPï¼‰")
    
    # è¯¦ç»†è¯´æ˜
    st.markdown("""
    ### å·¥å…·è¯´æ˜
    è¿™ä¸ªå·¥å…·ä¸“ä¸ºæ—¥æœ¬å¸‚åœºï¼ˆJPï¼‰è®¾è®¡ï¼Œç”¨äºä»ä¸Šä¼ çš„è°ƒæŸ¥ Excel æ–‡ä»¶è‡ªåŠ¨ç”Ÿæˆå¹¿å‘Šæ´»åŠ¨çš„æ‰¹é‡æ¨¡æ¿ï¼ˆheader-JP.xlsxï¼‰ã€‚å®ƒæ”¯æŒä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š
    
    - **è‡ªåŠ¨æå–æ´»åŠ¨ä¿¡æ¯**ï¼šä» 'å¹¿å‘Šæ´»åŠ¨åç§°' åˆ—æå–ç‹¬ç‰¹æ´»åŠ¨ï¼Œå¹¶æ˜ å°„ CPCã€SKUã€é¢„ç®—ã€å¹¿å‘Šç»„é»˜è®¤ç«ä»·ã€å¹¿å‘Šä½å’Œç™¾åˆ†æ¯”ç­‰å‚æ•°ã€‚
    - **å…³é”®è¯å¤„ç†**ï¼šæ™ºèƒ½åŒ¹é…ç²¾å‡†è¯/å¹¿æ³›è¯/ASIN åˆ—ï¼Œæ”¯æŒå»é‡æ£€æŸ¥å’Œç±»åˆ«æå–ï¼ˆä¾‹å¦‚ suzhu/å®¿ä¸»ã€case/åŒ…/tapeï¼‰ã€‚
    - **å¦å®šå…³é”®è¯è§„åˆ™**ï¼š
      - å…¨å±€å¦å®šï¼šå¦å®šç²¾å‡†å’Œå¦å®šè¯ç»„ã€‚
      - äº¤å‰å¦å®šï¼šå®¿ä¸»ç»„å¦å®š case ç»„ç²¾å‡†è¯ï¼Œåä¹‹äº¦ç„¶ã€‚
      - é¢å¤–è§„åˆ™ï¼šå¹¿æ³›åŒ¹é…ç»„ä½¿ç”¨åŒç±»ç²¾å‡†è¯ä½œä¸ºå¦å®šï¼›å®¿ä¸»å¹¿æ³›ç»„æ·»åŠ é¢å¤–å¦å®šè¯ã€‚
    - **å•†å“å®šå‘**ï¼šè‡ªåŠ¨å¤„ç† ASIN åˆ—çš„æ­£å‘/å¦å®šå®šå‘ã€‚
    - **è¾“å‡ºç»“æ„**ï¼šç”ŸæˆåŒ…å«å¹¿å‘Šæ´»åŠ¨ã€ç«ä»·è°ƒæ•´ã€å¹¿å‘Šç»„ã€å•†å“å¹¿å‘Šã€å…³é”®è¯ã€å¦å®šå…³é”®è¯ã€å•†å“å®šå‘ç­‰å®ä½“çš„å®Œæ•´æ¨¡æ¿ã€‚
    
    **ä½¿ç”¨æ­¥éª¤**ï¼š
    1. ä¸Šä¼  .xlsx è°ƒæŸ¥æ–‡ä»¶ï¼ˆåŒ…å«å¿…è¦åˆ—å¦‚ 'å¹¿å‘Šæ´»åŠ¨åç§°'ã€å…³é”®è¯åˆ—ã€å¦å®šåˆ—ç­‰ï¼‰ã€‚
    2. ç‚¹å‡»â€œç”Ÿæˆè¡¨å¤´â€æŒ‰é’®ã€‚
    3. æŸ¥çœ‹é¢„è§ˆå’Œè°ƒè¯•ä¿¡æ¯ï¼Œä¸‹è½½ç”Ÿæˆçš„ header-JP.xlsx æ–‡ä»¶ã€‚
    
    **æ³¨æ„äº‹é¡¹**ï¼š
    - ç¡®ä¿å…³é”®è¯åˆ—æ— é‡å¤ï¼Œå¦åˆ™ç”Ÿæˆå°†ä¸­æ­¢ã€‚
    - æ—¥æœŸé»˜è®¤ä¸ºå½“å‰æ—¥æœŸè‡³å¹´åº•ï¼ˆå¯æ‰‹åŠ¨è°ƒæ•´æ¨¡æ¿ï¼‰ã€‚
    
    å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ç»“æ„æˆ–è”ç³»æ”¯æŒã€‚
    """)
    
    # æ–‡ä»¶ä¸Šä¼ ï¼ˆä¸æŒ‡å®šæ–‡ä»¶åï¼‰
    uploaded_file = st.file_uploader("ä¸Šä¼ è°ƒæŸ¥ Excel æ–‡ä»¶", type=['xlsx'])
    
    if uploaded_file is not None:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶å
        saved_file_name = uploaded_file.name
        with open(saved_file_name, 'wb') as f:
            f.write(uploaded_file.getbuffer())
        st.success(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å·²ä¿å­˜ä¸ºï¼š{saved_file_name}")
        
        # ç”Ÿæˆè¡¨å¤´
        if st.button("ç”Ÿæˆè¡¨å¤´"):
            generate_header_from_survey(survey_file=saved_file_name, output_file='header-JP.xlsx')
    else:
        st.info("è¯·ä¸Šä¼  .xlsx æ–‡ä»¶ä»¥å¼€å§‹ç”Ÿæˆã€‚")

if __name__ == "__main__":
    main()
